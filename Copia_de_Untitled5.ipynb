{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY7sHjFttz4WQRf6W4aRTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiven0805/Borraxxo/blob/main/Copia_de_Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "SuzyMpsPSl_Q",
        "outputId": "68d4efda-bdd7-4ae8-b8ff-1bd9b1ce82fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Predicciones:\n",
            "1: tiger con 88.38% de confianza\n",
            "2: tiger_cat con 4.55% de confianza\n",
            "3: jaguar con 0.35% de confianza\n",
            "Especie identificada: Tigre\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tigre'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "model = MobileNetV2(weights=\"imagenet\")\n",
        "\n",
        "class AnimalNode:\n",
        "    def __init__(self, especie, razas):\n",
        "        self.especie = especie\n",
        "        self.razas = razas\n",
        "        self.siguiente = None\n",
        "\n",
        "class AnimalLista:\n",
        "    def __init__(self):\n",
        "        self.cabeza = None\n",
        "\n",
        "    def agregar_animal(self, especie, razas):\n",
        "        nuevo_nodo = AnimalNode(especie, razas)\n",
        "        if not self.cabeza:\n",
        "            self.cabeza = nuevo_nodo\n",
        "        else:\n",
        "            actual = self.cabeza\n",
        "            while actual.siguiente:\n",
        "                  actual = actual.siguiente\n",
        "            actual.siguiente = nuevo_nodo\n",
        "\n",
        "    def encontrar_animal(self, predicted_race):\n",
        "        actual = self.cabeza\n",
        "        while actual:\n",
        "            if predicted_race in actual.razas:\n",
        "                return actual.especie\n",
        "            actual = actual.siguiente\n",
        "        return \"Especie no encontrada\"\n",
        "\n",
        "def identificar_animal(imagen_path, lista_animales):\n",
        "    imagen = load_img(imagen_path, target_size=(224, 224))\n",
        "    imagen_array = img_to_array(imagen)\n",
        "    imagen_array = np.expand_dims(imagen_array, axis=0)\n",
        "    imagen_array = preprocess_input(imagen_array)\n",
        "\n",
        "    predicciones = model.predict(imagen_array)\n",
        "    etiquetas = decode_predictions(predicciones, top=3)[0]\n",
        "\n",
        "    print(\"Predicciones:\")\n",
        "    for i, (id_imagenet, nombre, confianza) in enumerate(etiquetas):\n",
        "        print(f\"{i+1}: {nombre} con {confianza*100:.2f}% de confianza\")\n",
        "\n",
        "    raza_predicha = etiquetas[0][1]\n",
        "    resultado = lista_animales.encontrar_animal(raza_predicha)\n",
        "\n",
        "    print(f\"Especie identificada: {resultado}\")\n",
        "    return resultado\n",
        "\n",
        "animales = AnimalLista()\n",
        "animales.agregar_animal(\"Caballo\", [\"sorrel\"])\n",
        "animales.agregar_animal(\"Perro\", [\"Labrador_retriever\", \"malinois\",\"Doberman\"])\n",
        "animales.agregar_animal(\"Gato\", [\"Siamese_cat\", \"persian\"])\n",
        "animales.agregar_animal(\"Tigre\", [\"tiger\"])\n",
        "\n",
        "identificar_animal(\"/content/tigre.jpeg\", animales)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección nueva"
      ],
      "metadata": {
        "id": "ANJcwKjFrd7B"
      }
    }
  ]
}